{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6534ef",
   "metadata": {},
   "source": [
    "# ----  Supervised Learning  ----\n",
    " \n",
    "1. **Supervised Learning Fundamentals**  \n",
    "   - Definition: _Supervised learning algorithms_ trained on **labeled examples** i.e. for an input the desired output is known (input-output pairs).  \n",
    "   - Example: Email spam detection (spam vs. legitimate) or movie reviews (positive vs. negative).  \n",
    "   - Key Idea: Historical labeled data trains **models (network or ML algorithm)** to learn to predict future unlabeled data.  \n",
    "   \n",
    "\n",
    "2. **How it works: Neural Networks & Model Training**  \n",
    "   - Process:  \n",
    "     - Network receives a set of **_Input data + correct outputs_** ‚Üí Model compares predictions (outputs by model) vs. actuals correct outputs (label)  \n",
    "     - According to comparison, the model **_adjusts_** weights/biases to minimize errors (through a process like backpropagation.).  \n",
    "   - Key Terms: *Weights*, *bias values* (we'll discuss in neural network theory).  \n",
    "\n",
    "### Supervised Learning Pipeline\n",
    "Supervised learning is often used in applications where patterns in past data help forecast likely future events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebae136",
   "metadata": {},
   "source": [
    "# üìä Data Science Notes  \n",
    "\n",
    "---\n",
    "\n",
    "## **üìå Data Pipeline for Supervised Learning**\n",
    "\n",
    "1. **Data Acquisition**  \n",
    "   - Where to get data.  \n",
    "   - **Sources:** Customer data, online databases, physical sensors, etc.\n",
    "\n",
    "2. **Data Cleaning & Formatting**  \n",
    "   - Clean and format data so that the model (e.g., Neural Network) can process it.  \n",
    "   - **Tools:** Libraries like Pandas for preprocessing.\n",
    "\n",
    "3. **Train-Test Split**  \n",
    "   - Typical ratio: **70% training / 30% testing**.\n",
    "\n",
    "4. **Model Training**  \n",
    "   - Use the **training set** to fit the model/network's parameters.\n",
    "\n",
    "5. **Model Testing**  \n",
    "   - Evaluate performance using the **test set**.  \n",
    "   - Compare **model output/predictions** with **actual labels**.  \n",
    "   - If performance is unsatisfactory, go back to **step 4** and adjust hyperparameters (e.g., add more NN layers).\n",
    "\n",
    "6. **Deployment**  \n",
    "   - If the model performs well, deploy it to production or a real-world application.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Note  \n",
    "\n",
    "The pipeline above is a **simplified version** ‚Äî it has a flaw.\n",
    "\n",
    "**Single train-test split isn't ideal** for evaluating our models performance because:\n",
    "- After building the model using \"Train data\" and we test our model using \"Test data\" we get some sort of **Performance Metric**\n",
    "- After tuning the model based on test set performance, the test set is no longer \"unseen\".\n",
    "- This leads to biased (over-optimistic) performance metrics.\n",
    "\n",
    "---\n",
    "\n",
    "It‚Äôs not fair to use the accuracy from the test data as the final performance metric for our model.  \n",
    "After all, if we **_repeatedly use the test data_** to evaluate and adjust the model's hyperparameters, it stops being an unbiased, unseen dataset.   \n",
    "\n",
    "**To address this issue, we split the dataset into three sets:**  \n",
    "- **Training Set**  \n",
    "- **Validation Set**  \n",
    "- **Test Set**\n",
    "\n",
    "This 3-way split is a standard approach in machine learning and deep learning tasks to ensure reliable and fair model evaluation.\n",
    "\n",
    "  \n",
    "## ‚úÖ **Model Evaluation** : Better Approach: 3-Way Data Split  \n",
    "\n",
    "   - **Problem:** Using the same test set repeatedly to tweak models ‚Üí \"cheating\" (data leakage).  \n",
    "   - **Solution:** Introduce a **validation set** (3-way split: train/validate/test).  \n",
    "\n",
    "**Split into:**\n",
    "- **Training Set:** Used to fit/train the model parameters. look at the features, correct output and fit on this Train Data\n",
    "- **Validation Set:**  \n",
    "  - Its a kind of test data  \n",
    "  - Used to tune hyperparameters (e.g. adding more NN layers, learning rate, neurons or change the NN architecture).  \n",
    "  - Check performance on this set during development.  \n",
    "  - we check the performance of our model using **_Performance Metric_** and adjust the hyperparameters  \n",
    "  - we repeat his process untill out models performance in satisfactory level on the **_Validation data_**  \n",
    "- **Test Set:**  \n",
    "  - Final, unseen data to evaluate the model‚Äôs real-world true performance.  \n",
    "  - gives final performance metric  \n",
    "  - No tweaking allowed (no updating weights or parameters) after test-set evaluation.  \n",
    "\n",
    "**Why?**  \n",
    "Using the validation set prevents **data leakage** and ensures the final test set reflects real-world performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Model Evaluation Summary**\n",
    "\n",
    "- **Problem:** Repeatedly tweaking based on test set ‚Üí cheating.\n",
    "- **Solution:** Use a **validation set** during model development.\n",
    "\n",
    "| Set Type        | Purpose                                 |\n",
    "|:----------------|:-----------------------------------------|\n",
    "| **Training Set**  | Fit model parameters.                    |\n",
    "| **Validation Set**| Tune hyperparameters, adjust architecture.|\n",
    "| **Test Set**      | Final unbiased performance evaluation.   |\n",
    "\n",
    "**Critical Point:**  \n",
    "- No further tweaks after evaluating on the **test set**.  \n",
    "- This final score reflects the model's true generalization ability.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Course Simplification  \n",
    "- The course uses **train-test split only** for exercises.\n",
    "- In real projects, **train-validate-test** is essential.\n",
    "\n",
    "---\n",
    "\n",
    "## **Performance Metrics**\n",
    "- **For Regression:** Root Mean Squared Error (RMSE)\n",
    "- **For Classification:** Accuracy, Precision, Recall, F1 Score, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## **Hyperparameters vs. Parameters**\n",
    "\n",
    "| Type             | Description                                | Example                 |\n",
    "|:----------------|:--------------------------------------------|:------------------------|\n",
    "| **Parameters**    | Learned by the model during training        | Weights, Biases          |\n",
    "| **Hyperparameters**| Set before training (manual or automated) | Learning rate, layers, batch size |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
